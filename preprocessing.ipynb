{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Library\n",
    "\n",
    "1. Environment Setup: import required libraries\n",
    "2. Calculating Features Statistic Data\n",
    "3. Preprocessing Data\n",
    "4. Building the Model\n",
    "5. Training Data\n",
    "6. Evalutaing Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup: import required library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculating Feature Statistic Data\n",
    "\n",
    "We will write a function to calculate the training and validating data. The mean, maximum, standard deviation, and variance are returned at the end of the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feat_stat(arr):\n",
    "    arr = [ f.reshape((-1, f.shape[-1])) for f in arr ]\n",
    "    arr = np.concatenate(arr)\n",
    "\n",
    "    return {\n",
    "            'max': np.max(arr, axis=0),\n",
    "            'mean': np.mean(arr, axis=0, dtype=np.float128),\n",
    "            'stdev': np.nanstd(arr, axis=0, dtype=np.float128),\n",
    "            'var': np.nanvar(arr, axis=0, dtype=np.float128),\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    A = np.arange(2*3*6).reshape((2,3,6))\n",
    "\n",
    "    stat = get_feat_stat([A])\n",
    "\n",
    "    # stat = get_feat_stat(X_train_orig)\n",
    "    print(\"create a simple matrix: \", A.shape, \"\\n\", A)\n",
    "    print(\"maximum:\", stat['max'])\n",
    "    print(\"mean:\", stat['mean'])\n",
    "    print(\"standard deviation:\", stat['stdev'])\n",
    "    print(\"variance:\", stat['var'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Preprocessing Input Data\n",
    "\n",
    "We will write the data processing functions in the section. There are three steps for input data:\n",
    "\n",
    "1. Standardize the data\n",
    "2. Expand the features by window slice\n",
    "3. Undersampling Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1. Standardize the data\n",
    "\n",
    "Next, we will standardize the data by calculating **stat** from the previous step. \n",
    "\n",
    "How to standardize the data: https://stackoverflow.com/a/4544459\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(A, stat):\n",
    "#     if isinstance(A, list):\n",
    "#         return [ standardize(a, stat) for a in A ]\n",
    "\n",
    "    A = np.subtract(A, stat['mean'])\n",
    "    A = np.divide(A, stat['stdev'])\n",
    "    A = A.astype(np.float32)\n",
    "\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    A = np.arange(2*3*6).reshape((2,3,6))\n",
    "    stat = get_feat_stat([A])\n",
    "\n",
    "    print(\"before standardization:\", A.shape, \"\\n\", A)\n",
    "    A = standardize(A, stat)\n",
    "    print(\"after standardization:\", A.shape, \"\\n\", A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2. Expand the features by window slice\n",
    "\n",
    "How to expand the features by window size: https://zhuanlan.zhihu.com/p/64933417\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "A = np.arange(5*3*6).reshape((5,3,6))\n",
    "window_size = 5\n",
    "\n",
    "A = np.arange(0,5*3*6,1).reshape((5,3,6)).astype(np.float128)\n",
    "A = np.pad(A, ((2,2), (2,2), (0,0)), mode='constant')\n",
    "A = strided(A, shape=(5,3,5,5,6), strides=(672,96,672,96,16))\n",
    "A = A.reshape((5,3,150))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(A, window_size):\n",
    "    if not window_size & 0x1:\n",
    "        raise Exception('need odd value on padding')\n",
    "\n",
    "#     if isinstance(A, list):\n",
    "#         return [ expand(a, window_size) for a in A ]\n",
    "\n",
    "    n = window_size # the height and width of the window\n",
    "    p = window_size >> 1 # the padding size\n",
    "\n",
    "    d0, d1, d2 = A.shape # dimansion 0, 1, 2\n",
    "    s0, s1, s2 = A.strides # stride 0, 1, 2\n",
    "\n",
    "    A = np.pad(A, pad_width=((p,p),(p,p),(0,0)), mode='constant')\n",
    "    A = np.lib.stride_tricks.as_strided(A, shape=(d0,d1,n,n,d2), strides=(s0,s1,s0,s1,s2))\n",
    "\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    A = np.arange(5*3*6).reshape((5,3,6))\n",
    "    window_size = 5\n",
    "\n",
    "    print(\"window size:\", window_size)\n",
    "    print(\"before expand:\", A.shape, A.strides)\n",
    "    A = expand(A, window_size)\n",
    "    print(\"after expand:\", A.shape, A.strides)\n",
    "    print(A[-1][-1][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3. Undersampling Data\n",
    "\n",
    "Because of the large data, we need to undersample the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample(arr, idx):\n",
    "    if isinstance(arr, list):\n",
    "        return [undersample(f, i) for f, i in zip(arr, idx)]\n",
    "    return arr[idx[:,1],idx[:,0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    A = np.arange(2*3*5*5*6).reshape((2,3,5,5,6))\n",
    "    sample = np.array([[2,1],[0,1],[1,0]])\n",
    "\n",
    "    print(\"the sample indices:\\n\", sample)\n",
    "    print(\"before undersampling shape:\", A.shape)\n",
    "    A = undersample(A, sample)\n",
    "    print(\"after undersampling shape:\", A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Preprocessing Output Data\n",
    "\n",
    "The target will be classified into two categories. \n",
    "\n",
    "- the target value is zero \n",
    "- the target vlaue is not zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(A):\n",
    "    if isinstance(A, list):\n",
    "        return [ classify(a) for a in A ]\n",
    "\n",
    "    A = A != 0\n",
    "    A = A.astype(int)\n",
    "\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    A = np.arange(2*3*1).reshape((2,3,1))\n",
    "\n",
    "    print(\"before classification:\\n\", A)\n",
    "    A = classify(A)\n",
    "    print(\"after classification:\\n\", A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
