{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Kernel Approximation\n",
    "\n",
    "1. Environment Setup: import required libraries\n",
    "2. Loading Dataset: training set, validation set, test set\n",
    "3. Preprocessing Data\n",
    "4. Building the Model\n",
    "5. Training Data\n",
    "6. Validating Data\n",
    "7. Testing Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup: import required library\n",
    "\n",
    "We include the required libraries that will be used in the next parts. The **time**, **numpy**, and **tensorflow** are common libraries in machine learning. The **fio**, which is \"file input output\" used to load data and **config**, which is \"configuration file\" used to config the path of the dataset files are written by myself. Modify it when you need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akiicat/opt/anaconda3/envs/universe/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/akiicat/opt/anaconda3/envs/universe/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/akiicat/opt/anaconda3/envs/universe/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/akiicat/opt/anaconda3/envs/universe/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/akiicat/opt/anaconda3/envs/universe/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/akiicat/opt/anaconda3/envs/universe/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/akiicat/opt/anaconda3/envs/universe/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import fio\n",
    "import preprocessing as pc\n",
    "from config import *\n",
    "import utility\n",
    "\n",
    "# python std library\n",
    "import itertools\n",
    "\n",
    "# install library\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Dataset: training set, validation set, test set\n",
    "\n",
    "Loading the training set, validation set, and test set that was defined in **config.py** file. Sample files consisting of indices of data will be used to undersample the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of training set: 3\n",
      "the length of testing set: 2\n",
      "the first row training data: [5.3 4.3 1.5 5.4 7.7 7.9]\n",
      "the first row target value: [1.]\n"
     ]
    }
   ],
   "source": [
    "X_train_orig = fio.load_file(X_train_dataset)\n",
    "Y_train_orig = fio.load_file(Y_train_dataset)\n",
    "X_test_orig = fio.load_file(X_test_dataset)\n",
    "Y_test_orig = fio.load_file(Y_test_dataset)\n",
    "\n",
    "print(\"the length of training set:\", len(X_train_orig))\n",
    "print(\"the length of testing set:\", len(X_test_orig))\n",
    "print(\"the first row training data:\", X_train_orig[0][0][0])\n",
    "print(\"the first row target value:\", Y_train_orig[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing Data\n",
    "\n",
    "There are two parts of the data that must be processed:\n",
    "\n",
    "- the input data represented by the prefix \"**X**\" on variables\n",
    "- the target data represented by the prefix \"**Y**\" on variables\n",
    "\n",
    "Check out the file **preprocess.py** for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X_lists, Y_lists, statistic, window_size=1, samples=[]):\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    def _callback(x, y):\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        \n",
    "    pc.iterative_all(X_lists, Y_lists, statistic, window_size=window_size, samples=samples, callback=_callback)\n",
    "        \n",
    "    X = np.concatenate(X, axis=0)\n",
    "    Y = np.concatenate(Y, axis=0)\n",
    "    \n",
    "    X = X.reshape((X.shape[0],-1))\n",
    "    Y = Y.reshape((Y.shape[0],-1))\n",
    "    \n",
    "    print(X.shape, utility.sizeof_fmt(X.nbytes))\n",
    "    print(Y.shape, utility.sizeof_fmt(Y.nbytes))\n",
    "    \n",
    "    return (X, Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size: 15 (5, 3, 6) --> (12, 3174) 148.8KiB 96.0B\n",
      "data size: 50 (10, 5, 6) --> (45, 3174) 557.9KiB 360.0B\n",
      "data size: 20000 (200, 100, 6) --> (16035, 3174) 194.1MiB 125.3KiB\n",
      "(16092, 3174) 194.8MiB\n",
      "(16092, 1) 125.7KiB\n"
     ]
    }
   ],
   "source": [
    "w = 23 # window size\n",
    "stat = pc.get_feat_stat(X_train_orig)\n",
    "\n",
    "train_sample = fio.load_sample_file(train_sample_dataset)\n",
    "X_train, Y_train = preprocessing(X_train_orig, Y_train_orig, stat, window_size=w, samples=train_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building the Model\n",
    "\n",
    "The model that we used is followed by the article: [Improving Linear Models Using Explicit Kernel Methods](https://github.com/Debian/tensorflow/blob/master/tensorflow/contrib/kernel_methods/g3doc/tutorial.md).\n",
    "\n",
    "https://storage.googleapis.com/pub-tools-public-publication-data/pdf/18d86099a350df93f2bd88587c0ec6d118cc98e7.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(dim_in, dim_out, stddev=5.0, learning_rate=0.003, l2_regularization_strength=0.006):\n",
    "    \n",
    "    optimizer = tf.train.FtrlOptimizer(learning_rate=learning_rate, l2_regularization_strength=l2_regularization_strength)\n",
    "    \n",
    "    image_column = tf.contrib.layers.real_valued_column('data', dimension=dim_in)\n",
    "    kernel_mapper = tf.contrib.kernel_methods.RandomFourierFeatureMapper(input_dim=dim_in, output_dim=dim_out, stddev=stddev, name='rffm')\n",
    "\n",
    "    estimator = tf.contrib.kernel_methods.KernelLinearClassifier(n_classes=2, optimizer=optimizer, kernel_mappers={image_column: [kernel_mapper]})\n",
    "\n",
    "    return estimator\n",
    "    \n",
    "    # For Example: Linear Model without optimizer\n",
    "    # image_column = tf.contrib.layers.real_valued_column('data', dimension=784)\n",
    "    # estimator = tf.contrib.learn.LinearClassifier(feature_columns=[image_column], n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/40/1jhkx0kj6ld3fv5st6wpccsr0000gp/T/tmph7s3j4k8\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x625af2cf8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/var/folders/40/1jhkx0kj6ld3fv5st6wpccsr0000gp/T/tmph7s3j4k8'}\n"
     ]
    }
   ],
   "source": [
    "dim_in  = w * w * 6\n",
    "dim_out = w * w * 6 * 10\n",
    "stddev  = 5.0\n",
    "learning_rate = 0.003\n",
    "l2_regularization_strength = 0.006\n",
    "\n",
    "estimator = create_model(dim_in, dim_out, stddev, learning_rate, l2_regularization_strength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(estimator, X, Y, batch_size=128, epoch=1):\n",
    "    print(\"training data shape:\", X.shape, Y.shape)\n",
    "    print(\"training data memory:\", utility.sizeof_fmt(X.nbytes), utility.sizeof_fmt(Y.nbytes))\n",
    "\n",
    "    x = {'data':X}\n",
    "    y = Y\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(x, y, batch_size=batch, shuffle=True, num_epochs=epoch)\n",
    "    \n",
    "    start = time.time()\n",
    "    estimator.fit(input_fn=train_input_fn) # Train.\n",
    "    end = time.time()\n",
    "    print('Elapsed time: {} seconds'.format(end - start))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (16092, 3174) (16092, 1)\n",
      "training data memory: 194.8MiB 125.7KiB\n",
      "WARNING:tensorflow:From /Users/akiicat/opt/anaconda3/envs/universe/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py:173: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/40/1jhkx0kj6ld3fv5st6wpccsr0000gp/T/tmph7s3j4k8/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.6931475, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.889074\n",
      "INFO:tensorflow:loss = 0.6930704, step = 101 (112.478 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 126 into /var/folders/40/1jhkx0kj6ld3fv5st6wpccsr0000gp/T/tmph7s3j4k8/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.69321847.\n",
      "Elapsed time: 338.6771728992462 seconds\n"
     ]
    }
   ],
   "source": [
    "batch = 128\n",
    "epoch = 1\n",
    "\n",
    "train_model(estimator, X_train, Y_train, batch, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validating Data\n",
    "\n",
    "1. Evaluating Training Data\n",
    "2. Evaluating Validation Data\n",
    "3. Get The Prediction Data\n",
    "\n",
    "metrics\n",
    "\n",
    "https://tensorflow.google.cn/versions/r1.15/api_docs/python/tf/keras/metrics\n",
    "\n",
    "\n",
    "true false positive negative\n",
    "\n",
    "https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative\n",
    "\n",
    "\n",
    "https://ai.stackexchange.com/questions/6383/meaning-of-evaluation-metrics-in-tensorflow\n",
    "\n",
    "- loss: The current value of the loss. Either the sum of the losses, or the loss of the last batch.\n",
    "- global_step: Number of iterations.\n",
    "- AUC or Area Under the (ROC) Curve is quite complicated, but tells you something about the true/false positive rate. In short: the AUC is equal to the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one.\n",
    "- auc_precision_recall: Is the percentage of relevant intstances, among the retrieved instances, that have been retrieved over the total amount of relevant instances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(estimator, X, Y, statistic, batch=None):\n",
    "    \n",
    "    if batch == None:\n",
    "        batch = X.shape[0]\n",
    "    \n",
    "    x = {'data': X}\n",
    "    y = Y\n",
    "    \n",
    "    input_fn = tf.estimator.inputs.numpy_input_fn(x, y, batch_size=batch, shuffle=False, num_epochs=1)\n",
    "    \n",
    "    metric = estimator.evaluate(input_fn=input_fn)\n",
    "    metric['count'] = X.shape[0]\n",
    "    \n",
    "    return metric\n",
    "\n",
    "def evaluate_models(estimator, X_lists, Y_lists, statistic, window_size=1, samples=[], batch=None):\n",
    "\n",
    "    metrics = []\n",
    "    def _callback(X, Y):\n",
    "        metric = evaluate_model(estimator, X, Y, statistic, batch=batch)\n",
    "        metrics.append(metric)\n",
    "        print(\"evaluated metrics:\", metric)\n",
    "\n",
    "    pc.iterative_all(X_lists, Y_lists, statistic, window_size=window_size, samples=samples, callback=_callback)\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Evaluating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2020-01-25-15:40:40\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/40/1jhkx0kj6ld3fv5st6wpccsr0000gp/T/tmph7s3j4k8/model.ckpt-126\n",
      "INFO:tensorflow:Finished evaluation at 2020-01-25-15:43:01\n",
      "INFO:tensorflow:Saving dict for global step 126: accuracy = 0.5036664, accuracy/baseline_label_mean = 0.5036664, accuracy/threshold_0.500000_mean = 0.5036664, auc = 0.5, auc_precision_recall = 0.7518332, global_step = 126, labels/actual_label_mean = 0.5036664, labels/prediction_mean = 0.50049055, loss = 0.6931225, precision/positive_threshold_0.500000_mean = 0.5036664, recall/positive_threshold_0.500000_mean = 1.0\n",
      "training metrics (grouped): {'loss': 0.6931225, 'accuracy': 0.5036664, 'labels/prediction_mean': 0.50049055, 'labels/actual_label_mean': 0.5036664, 'accuracy/baseline_label_mean': 0.5036664, 'auc': 0.5, 'auc_precision_recall': 0.7518332, 'accuracy/threshold_0.500000_mean': 0.5036664, 'precision/positive_threshold_0.500000_mean': 0.5036664, 'recall/positive_threshold_0.500000_mean': 1.0, 'global_step': 126, 'count': 16092}\n",
      "data size: 15 (5, 3, 6) --> (12, 3174) 148.8KiB 96.0B\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2020-01-25-15:43:20\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/40/1jhkx0kj6ld3fv5st6wpccsr0000gp/T/tmph7s3j4k8/model.ckpt-126\n",
      "INFO:tensorflow:Finished evaluation at 2020-01-25-15:43:49\n",
      "INFO:tensorflow:Saving dict for global step 126: accuracy = 0.5833333, accuracy/baseline_label_mean = 0.5833333, accuracy/threshold_0.500000_mean = 0.5833333, auc = 0.49999997, auc_precision_recall = 0.79166657, global_step = 126, labels/actual_label_mean = 0.5833333, labels/prediction_mean = 0.5005359, loss = 0.69296914, precision/positive_threshold_0.500000_mean = 0.5833333, recall/positive_threshold_0.500000_mean = 1.0\n",
      "evaluated metrics: {'loss': 0.69296914, 'accuracy': 0.5833333, 'labels/prediction_mean': 0.5005359, 'labels/actual_label_mean': 0.5833333, 'accuracy/baseline_label_mean': 0.5833333, 'auc': 0.49999997, 'auc_precision_recall': 0.79166657, 'accuracy/threshold_0.500000_mean': 0.5833333, 'precision/positive_threshold_0.500000_mean': 0.5833333, 'recall/positive_threshold_0.500000_mean': 1.0, 'global_step': 126, 'count': 12}\n",
      "data size: 50 (10, 5, 6) --> (45, 3174) 557.9KiB 360.0B\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2020-01-25-15:43:58\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/40/1jhkx0kj6ld3fv5st6wpccsr0000gp/T/tmph7s3j4k8/model.ckpt-126\n",
      "INFO:tensorflow:Finished evaluation at 2020-01-25-15:44:26\n",
      "INFO:tensorflow:Saving dict for global step 126: accuracy = 0.53333336, accuracy/baseline_label_mean = 0.53333336, accuracy/threshold_0.500000_mean = 0.53333336, auc = 0.49999994, auc_precision_recall = 0.7666666, global_step = 126, labels/actual_label_mean = 0.53333336, labels/prediction_mean = 0.5005359, loss = 0.6930764, precision/positive_threshold_0.500000_mean = 0.53333336, recall/positive_threshold_0.500000_mean = 1.0\n",
      "evaluated metrics: {'loss': 0.6930764, 'accuracy': 0.53333336, 'labels/prediction_mean': 0.5005359, 'labels/actual_label_mean': 0.53333336, 'accuracy/baseline_label_mean': 0.53333336, 'auc': 0.49999994, 'auc_precision_recall': 0.7666666, 'accuracy/threshold_0.500000_mean': 0.53333336, 'precision/positive_threshold_0.500000_mean': 0.53333336, 'recall/positive_threshold_0.500000_mean': 1.0, 'global_step': 126, 'count': 45}\n",
      "data size: 20000 (200, 100, 6) --> (16035, 3174) 194.1MiB 125.3KiB\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2020-01-25-15:44:33\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/40/1jhkx0kj6ld3fv5st6wpccsr0000gp/T/tmph7s3j4k8/model.ckpt-126\n",
      "INFO:tensorflow:Finished evaluation at 2020-01-25-15:49:34\n",
      "INFO:tensorflow:Saving dict for global step 126: accuracy = 0.5035235, accuracy/baseline_label_mean = 0.5035235, accuracy/threshold_0.500000_mean = 0.5035235, auc = 0.5, auc_precision_recall = 0.7517618, global_step = 126, labels/actual_label_mean = 0.5035235, labels/prediction_mean = 0.5004903, loss = 0.6931223, precision/positive_threshold_0.500000_mean = 0.5035235, recall/positive_threshold_0.500000_mean = 1.0\n",
      "evaluated metrics: {'loss': 0.6931223, 'accuracy': 0.5035235, 'labels/prediction_mean': 0.5004903, 'labels/actual_label_mean': 0.5035235, 'accuracy/baseline_label_mean': 0.5035235, 'auc': 0.5, 'auc_precision_recall': 0.7517618, 'accuracy/threshold_0.500000_mean': 0.5035235, 'precision/positive_threshold_0.500000_mean': 0.5035235, 'recall/positive_threshold_0.500000_mean': 1.0, 'global_step': 126, 'count': 16035}\n",
      "training metrics: [{'loss': 0.69296914, 'accuracy': 0.5833333, 'labels/prediction_mean': 0.5005359, 'labels/actual_label_mean': 0.5833333, 'accuracy/baseline_label_mean': 0.5833333, 'auc': 0.49999997, 'auc_precision_recall': 0.79166657, 'accuracy/threshold_0.500000_mean': 0.5833333, 'precision/positive_threshold_0.500000_mean': 0.5833333, 'recall/positive_threshold_0.500000_mean': 1.0, 'global_step': 126, 'count': 12}, {'loss': 0.6930764, 'accuracy': 0.53333336, 'labels/prediction_mean': 0.5005359, 'labels/actual_label_mean': 0.53333336, 'accuracy/baseline_label_mean': 0.53333336, 'auc': 0.49999994, 'auc_precision_recall': 0.7666666, 'accuracy/threshold_0.500000_mean': 0.53333336, 'precision/positive_threshold_0.500000_mean': 0.53333336, 'recall/positive_threshold_0.500000_mean': 1.0, 'global_step': 126, 'count': 45}, {'loss': 0.6931223, 'accuracy': 0.5035235, 'labels/prediction_mean': 0.5004903, 'labels/actual_label_mean': 0.5035235, 'accuracy/baseline_label_mean': 0.5035235, 'auc': 0.5, 'auc_precision_recall': 0.7517618, 'accuracy/threshold_0.500000_mean': 0.5035235, 'precision/positive_threshold_0.500000_mean': 0.5035235, 'recall/positive_threshold_0.500000_mean': 1.0, 'global_step': 126, 'count': 16035}]\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_model(estimator, X_train, Y_train, stat, batch=128)\n",
    "print(\"training metrics (grouped):\", metrics)\n",
    "metrics = evaluate_models(estimator, X_train_orig, Y_train_orig, stat, window_size=w, samples=train_sample, batch=128)\n",
    "print(\"training metrics:\", metrics)\n",
    "\n",
    "# metric = evaluate_model(estimator, X_train, Y_train, stat, batch=128)\n",
    "# del X_train, Y_train\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Evaluating Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size: 15 (5, 3, 6) --> (3, 3174) 37.2KiB 24.0B\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2020-01-25-15:49:57\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/40/1jhkx0kj6ld3fv5st6wpccsr0000gp/T/tmph7s3j4k8/model.ckpt-126\n",
      "INFO:tensorflow:Finished evaluation at 2020-01-25-15:50:55\n",
      "INFO:tensorflow:Saving dict for global step 126: accuracy = 0.33333334, accuracy/baseline_label_mean = 0.33333334, accuracy/threshold_0.500000_mean = 0.33333334, auc = 0.50000024, auc_precision_recall = 0.6666661, global_step = 126, labels/actual_label_mean = 0.33333334, labels/prediction_mean = 0.5005359, loss = 0.69350505, precision/positive_threshold_0.500000_mean = 0.33333334, recall/positive_threshold_0.500000_mean = 0.9999999\n",
      "evaluated metrics: {'loss': 0.69350505, 'accuracy': 0.33333334, 'labels/prediction_mean': 0.5005359, 'labels/actual_label_mean': 0.33333334, 'accuracy/baseline_label_mean': 0.33333334, 'auc': 0.50000024, 'auc_precision_recall': 0.6666661, 'accuracy/threshold_0.500000_mean': 0.33333334, 'precision/positive_threshold_0.500000_mean': 0.33333334, 'recall/positive_threshold_0.500000_mean': 0.9999999, 'global_step': 126, 'count': 3}\n",
      "data size: 50 (10, 5, 6) --> (5, 3174) 62.0KiB 40.0B\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2020-01-25-15:51:10\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/40/1jhkx0kj6ld3fv5st6wpccsr0000gp/T/tmph7s3j4k8/model.ckpt-126\n",
      "INFO:tensorflow:Finished evaluation at 2020-01-25-15:51:45\n",
      "INFO:tensorflow:Saving dict for global step 126: accuracy = 0.6, accuracy/baseline_label_mean = 0.6, accuracy/threshold_0.500000_mean = 0.6, auc = 0.49999994, auc_precision_recall = 0.7999998, global_step = 126, labels/actual_label_mean = 0.6, labels/prediction_mean = 0.5005359, loss = 0.69293344, precision/positive_threshold_0.500000_mean = 0.6, recall/positive_threshold_0.500000_mean = 1.0\n",
      "evaluated metrics: {'loss': 0.69293344, 'accuracy': 0.6, 'labels/prediction_mean': 0.5005359, 'labels/actual_label_mean': 0.6, 'accuracy/baseline_label_mean': 0.6, 'auc': 0.49999994, 'auc_precision_recall': 0.7999998, 'accuracy/threshold_0.500000_mean': 0.6, 'precision/positive_threshold_0.500000_mean': 0.6, 'recall/positive_threshold_0.500000_mean': 1.0, 'global_step': 126, 'count': 5}\n",
      "data size: 20000 (200, 100, 6) --> (3965, 3174) 48.0MiB 31.0KiB\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2020-01-25-15:52:01\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/40/1jhkx0kj6ld3fv5st6wpccsr0000gp/T/tmph7s3j4k8/model.ckpt-126\n",
      "INFO:tensorflow:Finished evaluation at 2020-01-25-15:53:48\n",
      "INFO:tensorflow:Saving dict for global step 126: accuracy = 0.49836066, accuracy/baseline_label_mean = 0.49836066, accuracy/threshold_0.500000_mean = 0.49836066, auc = 0.5, auc_precision_recall = 0.7491803, global_step = 126, labels/actual_label_mean = 0.49836066, labels/prediction_mean = 0.50049007, loss = 0.6931509, precision/positive_threshold_0.500000_mean = 0.49836066, recall/positive_threshold_0.500000_mean = 1.0\n",
      "evaluated metrics: {'loss': 0.6931509, 'accuracy': 0.49836066, 'labels/prediction_mean': 0.50049007, 'labels/actual_label_mean': 0.49836066, 'accuracy/baseline_label_mean': 0.49836066, 'auc': 0.5, 'auc_precision_recall': 0.7491803, 'accuracy/threshold_0.500000_mean': 0.49836066, 'precision/positive_threshold_0.500000_mean': 0.49836066, 'recall/positive_threshold_0.500000_mean': 1.0, 'global_step': 126, 'count': 3965}\n",
      "validation metrics: [{'loss': 0.69350505, 'accuracy': 0.33333334, 'labels/prediction_mean': 0.5005359, 'labels/actual_label_mean': 0.33333334, 'accuracy/baseline_label_mean': 0.33333334, 'auc': 0.50000024, 'auc_precision_recall': 0.6666661, 'accuracy/threshold_0.500000_mean': 0.33333334, 'precision/positive_threshold_0.500000_mean': 0.33333334, 'recall/positive_threshold_0.500000_mean': 0.9999999, 'global_step': 126, 'count': 3}, {'loss': 0.69293344, 'accuracy': 0.6, 'labels/prediction_mean': 0.5005359, 'labels/actual_label_mean': 0.6, 'accuracy/baseline_label_mean': 0.6, 'auc': 0.49999994, 'auc_precision_recall': 0.7999998, 'accuracy/threshold_0.500000_mean': 0.6, 'precision/positive_threshold_0.500000_mean': 0.6, 'recall/positive_threshold_0.500000_mean': 1.0, 'global_step': 126, 'count': 5}, {'loss': 0.6931509, 'accuracy': 0.49836066, 'labels/prediction_mean': 0.50049007, 'labels/actual_label_mean': 0.49836066, 'accuracy/baseline_label_mean': 0.49836066, 'auc': 0.5, 'auc_precision_recall': 0.7491803, 'accuracy/threshold_0.500000_mean': 0.49836066, 'precision/positive_threshold_0.500000_mean': 0.49836066, 'recall/positive_threshold_0.500000_mean': 1.0, 'global_step': 126, 'count': 3965}]\n"
     ]
    }
   ],
   "source": [
    "valid_sample = fio.load_sample_file(valid_sample_dataset)\n",
    "metrics = evaluate_models(estimator, X_train_orig, Y_train_orig, stat, window_size=w, samples=valid_sample, batch=128)\n",
    "print(\"validation metrics:\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_valid, Y_valid = preprocessing(X_train_orig, Y_train_orig, stat, window_size=w, samples=valid_sample)\n",
    "# metric = evaluate_model(estimator, X_valid, Y_valid, stat, batch=128)\n",
    "# del X_valid, Y_valid\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Get The Prediction Data\n",
    "\n",
    "```python\n",
    "x = {'data': X_train.astype(np.float32)}\n",
    "y = Y_train\n",
    "\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(x, batch_size=batch, shuffle=False)\n",
    "metric = estimator.predict(input_fn=input_fn)\n",
    "print(metric['classes'])\n",
    "```\n",
    "\n",
    "**Args:**\n",
    "\n",
    "- input_fn: Input function. If set, `x` and 'batch_size' must be `None`.\n",
    "\n",
    "**Returns:**\n",
    "\n",
    "A numpy array of predicted classes or regression values if the constructor's `model_fn` returns a `Tensor` for `predictions` or a `dict` of numpy arrays if `model_fn` returns a `dict`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_models(estimator, X_test_orig, Y_test_orig, stat, window_size=w, batch=128)\n",
    "print(\"testing metrics:\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
